{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "# Set the parent directory as the current directory\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = \"Mg\"\n",
    "def load_mistral_llm_client():\n",
    "    \"\"\"\n",
    "    Load a Mistral 24B LLM client configured with default cache directories\n",
    "    and assigned to cuda:0 device.\n",
    "    \n",
    "    Returns:\n",
    "        LocalLLMClient: Initialized LLM client for Mistral 24B\n",
    "    \"\"\"\n",
    "    from utils.llm_client import LocalLLMClient\n",
    "    \n",
    "    # Default cache directory from mine_hpo.py\n",
    "    default_cache_dir = \"/u/zelalae2/scratch/rdma_cache\"\n",
    "    \n",
    "    # Initialize and return the client with specific configuration\n",
    "    llm_client = LocalLLMClient(\n",
    "        model_type=\"mistral_24b\",  # Explicitly request mistral_24b model\n",
    "        device=\"cuda:0\",           # Assign to first GPU (cuda:0)\n",
    "        cache_dir=default_cache_dir,\n",
    "        temperature=0.0001           # Default temperature from mine_hpo.py\n",
    "    )\n",
    "    \n",
    "    return llm_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_abbreviation_searcher(retriever_type=\"sentence_transformer\", model_name=\"abhinand/MedEmbed-small-v0.1\"):\n",
    "    \"\"\"\n",
    "    Initialize the abbreviation searcher with embeddings file.\n",
    "    \n",
    "    Args:\n",
    "        retriever_type: Type of embedding model to use\n",
    "        model_name: Name of the embedding model\n",
    "        \n",
    "    Returns:\n",
    "        Initialized ToolSearcher for abbreviation lookups\n",
    "    \"\"\"\n",
    "    from utils.search_tools import ToolSearcher\n",
    "    from utils.embedding import EmbeddingsManager\n",
    "    \n",
    "    # Path to the embeddings file - adjust as needed\n",
    "    abbreviations_file = \"/home/johnwu3/projects/rare_disease/workspace/repos/RDMA/data/tools/abbreviations_medembed_sm.npy\"\n",
    "    \n",
    "    # Initialize embedding manager\n",
    "    embedding_manager = EmbeddingsManager(\n",
    "        model_type=retriever_type,\n",
    "        model_name=model_name,\n",
    "        device=\"cpu\"  # Use CPU to avoid GPU conflicts\n",
    "    )\n",
    "    \n",
    "    # Initialize abbreviation searcher\n",
    "    abbreviation_searcher = ToolSearcher(\n",
    "        model_type=retriever_type,\n",
    "        model_name=model_name,\n",
    "        device=\"cpu\",  # Use CPU for abbreviation searching\n",
    "        top_k=3  # Get top 3 matches for abbreviations\n",
    "    )\n",
    "    \n",
    "    # Load embeddings\n",
    "\n",
    "    abbreviation_searcher.load_embeddings(abbreviations_file)\n",
    "    print(\"Abbreviation searcher initialized successfully\")\n",
    "    return abbreviation_searcher\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def check_abbreviation_llm(entity, llm_client, system_message):\n",
    "    \"\"\"\n",
    "    Check if an entity is an abbreviation using LLM.\n",
    "    \n",
    "    Args:\n",
    "        entity: Entity text to check\n",
    "        llm_client: LLM client for querying\n",
    "        system_message: System message for LLM\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with abbreviation check results\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    # Create the prompt\n",
    "    abbreviation_prompt = f\"Is '{entity}' an abbreviation in medical or clinical context? \" + \\\n",
    "                         f\"Respond with ONLY 'YES' if it's an abbreviation or 'NO' if it's not.\"\n",
    "    \n",
    "    # Query the LLM\n",
    "    response = llm_client.query(abbreviation_prompt, system_message)\n",
    "    \n",
    "    # Parse the response\n",
    "    response_text = response.strip().upper()\n",
    "    is_abbreviation = \"YES\" in response_text and \"NO\" not in response_text\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return {\n",
    "        'is_abbreviation': is_abbreviation,\n",
    "        'confidence': 0.9 if is_abbreviation else 0.1,\n",
    "        'response': response,\n",
    "        'method': 'llm',\n",
    "        'execution_time': end_time - start_time\n",
    "    }\n",
    "\n",
    "\n",
    "def check_abbreviation_retrieval(entity, abbreviation_searcher):\n",
    "    \"\"\"\n",
    "    Check if an entity is an abbreviation using vector retrieval.\n",
    "    \n",
    "    Args:\n",
    "        entity: Entity text to check\n",
    "        abbreviation_searcher: ToolSearcher for abbreviation lookups\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with abbreviation check results\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Quick rule-based check to filter obvious non-abbreviations\n",
    "\n",
    "\n",
    "        # Search for abbreviation\n",
    "    search_results = abbreviation_searcher.search(entity)\n",
    "    \n",
    "    if not search_results:\n",
    "        result = {\n",
    "            'is_abbreviation': False,\n",
    "            'confidence': 0.9,\n",
    "            'method': 'no_match_found',\n",
    "            'execution_time': time.time() - start_time\n",
    "        }\n",
    "        return result\n",
    "   \n",
    "    # Get top result\n",
    "    top_result = search_results[0]\n",
    "    print(top_result)\n",
    "    similarity = top_result.get('similarity', 0.0)\n",
    "    query_term = top_result.get('query_term', '')\n",
    "    expanded_term = top_result.get('result', '')\n",
    "    \n",
    "    # Check if this is a good match\n",
    "    is_abbreviation = similarity > 0.98 and query_term == entity\n",
    "    \n",
    "    result = {\n",
    "        'is_abbreviation': is_abbreviation,\n",
    "        'expanded_term': expanded_term if is_abbreviation else None,\n",
    "        'confidence': similarity if is_abbreviation else (1.0 - similarity),\n",
    "        'method': 'abbreviation_lookup',\n",
    "        'top_matches': search_results[:3],  # Include top 3 matches\n",
    "        'execution_time': time.time() - start_time\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ModelLoader with cache directory: /shared/rsaas/jw3/rare_disease/model_cache\n",
      "Loading LLM!\n",
      "Device configuration: cuda:0\n",
      "Using device map: {'': 'cuda:0'}\n",
      "Loading 70B model with quantization: mistral_24b\n",
      "Generated cache path: /shared/rsaas/jw3/rare_disease/model_cache/Mistral-Small-24B-Instruct-2501_4bit_nf4\n",
      "Valid cache found at /shared/rsaas/jw3/rare_disease/model_cache/Mistral-Small-24B-Instruct-2501_4bit_nf4\n",
      "Loading cached quantized model from /shared/rsaas/jw3/rare_disease/model_cache/Mistral-Small-24B-Instruct-2501_4bit_nf4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnwu3/miniconda3/envs/hporag/lib/python3.10/site-packages/transformers/quantizers/auto.py:206: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b2660417f04379863a64fd270712ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here to help. How can I assist you today? If you have any medical questions or need information on a specific topic, feel free to ask. Please note that while I strive to provide accurate and helpful information, I am an AI and my knowledge cutoff is 2023, so I might not have real-time or up-to-date information. For urgent medical concerns, always consult a healthcare professional.\n",
      "\n",
      "Here are a few examples of how I can assist you:\n",
      "\n",
      "* Explain medical terms or concepts\n",
      "* Provide information on diseases, symptoms, and treatments\n",
      "* Offer insights into medical procedures and tests\n",
      "* Discuss healthcare guidelines and recommendations\n",
      "* Answer questions related to biomedical research and studies\n",
      "\n",
      "What would you like to know or discuss?\n",
      "Loading model...\n",
      "Model type: sentence_transformer\n",
      "Model name: abhinand/MedEmbed-small-v0.1\n",
      "Device: cpu\n",
      "Initializing SentenceTransformer with model: abhinand/MedEmbed-small-v0.1 on device: cpu\n",
      "Model running on CPU\n",
      "Verifying model by embedding sample text...\n",
      "Model initialized successfully. Embedding dimension: 384\n",
      "Loading model...\n",
      "Model type: sentence_transformer\n",
      "Model name: abhinand/MedEmbed-small-v0.1\n",
      "Device: cpu\n",
      "Initializing SentenceTransformer with model: abhinand/MedEmbed-small-v0.1 on device: cpu\n",
      "Model running on CPU\n",
      "Verifying model by embedding sample text...\n",
      "Model initialized successfully. Embedding dimension: 384\n",
      "Loading embeddings from /home/johnwu3/projects/rare_disease/workspace/repos/RDMA/data/tools/abbreviations_medembed_sm.npy\n",
      "Loaded 2150 embedded documents\n",
      "Created FAISS index with 2150 vectors of dimension 384\n",
      "Abbreviation searcher initialized successfully\n",
      "Running benchmark on 19 test cases...\n",
      "\n",
      "Testing entity: 'Mg'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'Mg', 'matched_term': 'MG', 'result': 'myasthenia gravis'}\n",
      "  LLM: True (0.385s)\n",
      "  Retrieval: True (0.016s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'CHF'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'CHF', 'matched_term': 'CHF', 'result': 'congestive heart failure'}\n",
      "  LLM: True (0.380s)\n",
      "  Retrieval: True (0.013s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'MI'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'MI', 'matched_term': 'MI', 'result': 'myocardial infarction; mitral insufficiency'}\n",
      "  LLM: True (0.380s)\n",
      "  Retrieval: True (0.012s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'HTN'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'HTN', 'matched_term': 'HTN', 'result': 'hypertension'}\n",
      "  LLM: True (0.381s)\n",
      "  Retrieval: True (0.018s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'DM'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'DM', 'matched_term': 'DM', 'result': 'diabetes mellitus'}\n",
      "  LLM: True (0.383s)\n",
      "  Retrieval: True (0.012s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'PKU'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'PKU', 'matched_term': 'PKU', 'result': 'phenylketonuria'}\n",
      "  LLM: True (0.384s)\n",
      "  Retrieval: True (0.013s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'CF'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'CF', 'matched_term': 'Cf', 'result': 'calfornium'}\n",
      "  LLM: True (0.382s)\n",
      "  Retrieval: True (0.014s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'DMD'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'DMD', 'matched_term': 'DMD', 'result': 'Doctor of Dental Medicine; Duchenne muscular dystrophy'}\n",
      "  LLM: True (0.382s)\n",
      "  Retrieval: True (0.014s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'HF'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'HF', 'matched_term': 'HF', 'result': 'heart failure'}\n",
      "  LLM: True (0.381s)\n",
      "  Retrieval: True (0.013s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'MS'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'MS', 'matched_term': 'MS', 'result': 'mitral stenosis; multiple sclerosis; Master of Science'}\n",
      "  LLM: True (0.381s)\n",
      "  Retrieval: True (0.013s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'DNA'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'DNA', 'matched_term': 'DNA', 'result': 'deoxyribonucleic acid'}\n",
      "  LLM: True (0.381s)\n",
      "  Retrieval: True (0.012s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'LASER'\n",
      "{'rank': 1, 'similarity': 0.6480345766434613, 'query_term': 'LASER', 'matched_term': 'TORCH', 'result': 'toxoplasmosis, other, rubella, cytomegalovirus, and herpes simplex (maternal infections)'}\n",
      "  LLM: True (0.381s)\n",
      "  Retrieval: False (0.012s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'RARE'\n",
      "{'rank': 1, 'similarity': 0.6727873338276882, 'query_term': 'RARE', 'matched_term': 'LOT', 'result': 'left occipitotransverse (fetal position)'}\n",
      "  LLM: False (0.380s)\n",
      "  Retrieval: False (0.012s)\n",
      "  Expected: False\n",
      "\n",
      "Testing entity: 'disease'\n",
      "{'rank': 1, 'similarity': 0.675006241222809, 'query_term': 'disease', 'matched_term': 'STD', 'result': 'sexually transmitted disease'}\n",
      "  LLM: False (0.381s)\n",
      "  Retrieval: False (0.013s)\n",
      "  Expected: False\n",
      "\n",
      "Testing entity: 'syndrome'\n",
      "{'rank': 1, 'similarity': 0.6805540718641975, 'query_term': 'syndrome', 'matched_term': 's', 'result': 'sine; without'}\n",
      "  LLM: False (0.381s)\n",
      "  Retrieval: False (0.012s)\n",
      "  Expected: False\n",
      "\n",
      "Testing entity: 'patient'\n",
      "{'rank': 1, 'similarity': 0.6517189784478294, 'query_term': 'patient', 'matched_term': 'DOC', 'result': 'deoxycholic acid; deoxycorticosterone'}\n",
      "  LLM: False (0.382s)\n",
      "  Retrieval: False (0.013s)\n",
      "  Expected: False\n",
      "\n",
      "Testing entity: 'IQ'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'IQ', 'matched_term': 'IQ', 'result': 'intelligence quotient'}\n",
      "  LLM: False (0.381s)\n",
      "  Retrieval: True (0.012s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'pH'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'pH', 'matched_term': 'pH', 'result': 'hydrogen ion concentration'}\n",
      "  LLM: True (0.381s)\n",
      "  Retrieval: True (0.012s)\n",
      "  Expected: True\n",
      "\n",
      "Testing entity: 'mm'\n",
      "{'rank': 1, 'similarity': 1.0, 'query_term': 'mm', 'matched_term': 'MM', 'result': 'mucous membrane; multiple myeloma'}\n",
      "  LLM: True (0.381s)\n",
      "  Retrieval: True (0.012s)\n",
      "  Expected: True\n",
      "\n",
      "=== Benchmark Summary ===\n",
      "Total test cases: 19\n",
      "LLM average time: 0.381s\n",
      "Retrieval average time: 0.013s\n",
      "Time improvement: 96.6%\n",
      "LLM accuracy: 0.95 (18/19)\n",
      "Retrieval accuracy: 0.95 (18/19)\n",
      "Benchmark results saved to abbreviation_benchmark_20250421-114522.json\n"
     ]
    }
   ],
   "source": [
    "def benchmark_abbreviation_detection(test_cases, llm_client, abbreviation_searcher):\n",
    "    \"\"\"\n",
    "    Benchmark LLM vs. retrieval approaches for abbreviation detection.\n",
    "    \n",
    "    Args:\n",
    "        test_cases: List of dictionaries with entity and expected result\n",
    "        llm_client: LLM client for querying\n",
    "        abbreviation_searcher: ToolSearcher for abbreviation lookups\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with benchmark results\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    system_message = \"You are a medical expert specializing in clinical terminology and abbreviations.\"\n",
    "    results = []\n",
    "    \n",
    "    llm_times = []\n",
    "    retrieval_times = []\n",
    "    llm_correct = 0\n",
    "    retrieval_correct = 0\n",
    "    \n",
    "    print(f\"Running benchmark on {len(test_cases)} test cases...\")\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases):\n",
    "        entity = test_case['entity']\n",
    "        expected = test_case.get('expected', None)\n",
    "        \n",
    "        print(f\"\\nTesting entity: '{entity}'\")\n",
    "        \n",
    "        # Test LLM approach\n",
    "        llm_result = check_abbreviation_llm(entity, llm_client, system_message)\n",
    "        llm_times.append(llm_result['execution_time'])\n",
    "        \n",
    "        # Test retrieval approach\n",
    "        retrieval_result = check_abbreviation_retrieval(entity, abbreviation_searcher)\n",
    "        retrieval_times.append(retrieval_result['execution_time'])\n",
    "        \n",
    "        # Check correctness if expected result is provided\n",
    "        if expected is not None:\n",
    "            if llm_result['is_abbreviation'] == expected:\n",
    "                llm_correct += 1\n",
    "                \n",
    "            if retrieval_result['is_abbreviation'] == expected:\n",
    "                retrieval_correct += 1\n",
    "        \n",
    "        # Store results\n",
    "        case_result = {\n",
    "            'entity': entity,\n",
    "            'expected': expected,\n",
    "            'llm_result': llm_result,\n",
    "            'retrieval_result': retrieval_result\n",
    "        }\n",
    "        results.append(case_result)\n",
    "        \n",
    "        # Print summary for this test case\n",
    "        print(f\"  LLM: {llm_result['is_abbreviation']} ({llm_result['execution_time']:.3f}s)\")\n",
    "        print(f\"  Retrieval: {retrieval_result['is_abbreviation']} ({retrieval_result['execution_time']:.3f}s)\")\n",
    "        if expected is not None:\n",
    "            print(f\"  Expected: {expected}\")\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    avg_llm_time = sum(llm_times) / len(llm_times) if llm_times else 0\n",
    "    avg_retrieval_time = sum(retrieval_times) / len(retrieval_times) if retrieval_times else 0\n",
    "    \n",
    "    total_with_expected = sum(1 for test in test_cases if test.get('expected') is not None)\n",
    "    llm_accuracy = llm_correct / total_with_expected if total_with_expected > 0 else 0\n",
    "    retrieval_accuracy = retrieval_correct / total_with_expected if total_with_expected > 0 else 0\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n=== Benchmark Summary ===\")\n",
    "    print(f\"Total test cases: {len(test_cases)}\")\n",
    "    print(f\"LLM average time: {avg_llm_time:.3f}s\")\n",
    "    print(f\"Retrieval average time: {avg_retrieval_time:.3f}s\")\n",
    "    print(f\"Time improvement: {(avg_llm_time - avg_retrieval_time) / avg_llm_time * 100:.1f}%\")\n",
    "    \n",
    "    if total_with_expected > 0:\n",
    "        print(f\"LLM accuracy: {llm_accuracy:.2f} ({llm_correct}/{total_with_expected})\")\n",
    "        print(f\"Retrieval accuracy: {retrieval_accuracy:.2f} ({retrieval_correct}/{total_with_expected})\")\n",
    "    \n",
    "    return {\n",
    "        'detailed_results': results,\n",
    "        'summary': {\n",
    "            'avg_llm_time': avg_llm_time,\n",
    "            'avg_retrieval_time': avg_retrieval_time,\n",
    "            'llm_accuracy': llm_accuracy,\n",
    "            'retrieval_accuracy': retrieval_accuracy,\n",
    "            'llm_correct': llm_correct,\n",
    "            'retrieval_correct': retrieval_correct,\n",
    "            'total_cases': len(test_cases),\n",
    "            'total_with_expected': total_with_expected\n",
    "        }\n",
    "    }\n",
    "\n",
    "def run_abbreviation_benchmark():\n",
    "    \"\"\"Main function to run the benchmark.\"\"\"\n",
    "    import time\n",
    "    \n",
    "    # Load LLM client\n",
    "    llm_client = load_mistral_llm_client()\n",
    "    \n",
    "    # Initialize abbreviation searcher\n",
    "    abbreviation_searcher = initialize_abbreviation_searcher()\n",
    "    \n",
    "    # Define test cases\n",
    "    test_cases = [\n",
    "        # Common medical abbreviations (should be detected by both methods)\n",
    "        {'entity': 'Mg', 'expected': True},  # Magnesium\n",
    "        {'entity': 'CHF', 'expected': True},  # Congestive Heart Failure\n",
    "        {'entity': 'MI', 'expected': True},  # Myocardial Infarction\n",
    "        {'entity': 'HTN', 'expected': True},  # Hypertension\n",
    "        {'entity': 'DM', 'expected': True},  # Diabetes Mellitus\n",
    "        \n",
    "        # Rare disease abbreviations (might be harder for retrieval)\n",
    "        {'entity': 'PKU', 'expected': True},  # Phenylketonuria\n",
    "        {'entity': 'CF', 'expected': True},  # Cystic Fibrosis\n",
    "        {'entity': 'DMD', 'expected': True},  # Duchenne Muscular Dystrophy\n",
    "        \n",
    "        # Ambiguous terms\n",
    "        {'entity': 'HF', 'expected': True},  # Heart Failure or Hydrofluoric Acid\n",
    "        {'entity': 'MS', 'expected': True},  # Multiple Sclerosis or Mass Spectrometry\n",
    "        \n",
    "        # Non-abbreviations that look like abbreviations\n",
    "        {'entity': 'DNA', 'expected': True},  # Technically an abbreviation\n",
    "        {'entity': 'LASER', 'expected': True},  # Originally an acronym\n",
    "        {'entity': 'RARE', 'expected': False},  # Just an uppercase word\n",
    "        \n",
    "        # Normal words (should not be detected as abbreviations)\n",
    "        {'entity': 'disease', 'expected': False},\n",
    "        {'entity': 'syndrome', 'expected': False},\n",
    "        {'entity': 'patient', 'expected': False},\n",
    "        \n",
    "        # Borderline cases\n",
    "        {'entity': 'IQ', 'expected': True},  # Intelligence Quotient\n",
    "        {'entity': 'pH', 'expected': True},  # Power of Hydrogen\n",
    "        {'entity': 'mm', 'expected': True},  # Millimeter\n",
    "        \n",
    "        # Additional test cases can be added here\n",
    "    ]\n",
    "    \n",
    "    # Run benchmark\n",
    "    benchmark_results = benchmark_abbreviation_detection(test_cases, llm_client, abbreviation_searcher)\n",
    "    \n",
    "    # Save results to file (optional)\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    result_file = f\"abbreviation_benchmark_{timestamp}.json\"\n",
    "    \n",
    "    import json\n",
    "    with open(result_file, 'w') as f:\n",
    "        json.dump(benchmark_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Benchmark results saved to {result_file}\")\n",
    "\n",
    "# Execute the benchmark\n",
    "if __name__ == \"__main__\":\n",
    "    run_abbreviation_benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hporag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
