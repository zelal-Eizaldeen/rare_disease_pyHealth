{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Nu-Extract, actual waste of time not worth reporting for healthcare tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "# Set the parent directory as the current directory\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "Pairwise checks:\n",
      "31\n",
      "48\n",
      "Pairwise checks:\n",
      "16\n",
      "25\n",
      "Pairwise checks:\n",
      "19\n",
      "22\n",
      "Pairwise checks:\n",
      "15\n",
      "22\n",
      "Pairwise checks:\n",
      "10\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "from utils.data import read_json_file, print_json_structure\n",
    "hpo_data = read_json_file('data/dataset/mine_hpo.json')\n",
    "print(len(hpo_data))\n",
    "# print_json_structure(hpo_data)\n",
    "truth = hpo_data[\"53\"][\"phenotypes\"]\n",
    "# sample 5 texts and their ground truth phenotypes for testing.\n",
    "ids = [\"53\", \"54\", \"55\", \"56\", \"57\"] \n",
    "texts = []\n",
    "ground_truths = []\n",
    "for id in ids:\n",
    "    text = hpo_data[id][\"clinical_text\"]\n",
    "    texts.append(text)\n",
    "    truth = hpo_data[id][\"phenotypes\"]\n",
    "    ground_truth = []\n",
    "    for item in truth:\n",
    "        ground_truth.append(item[\"phenotype_name\"])\n",
    "    ground_truths.append(ground_truth)\n",
    "\n",
    "    sanity_check_list = []\n",
    "    for item in ground_truth:\n",
    "        # print(item)\n",
    "        if item in text:\n",
    "            sanity_check_list.append(item)\n",
    "    print(\"Pairwise checks:\")\n",
    "    print(len(sanity_check_list))\n",
    "    print(len(truth))\n",
    "# ground_truth = []\n",
    "# for item in truth:\n",
    "#     ground_truth.append(item[\"phenotype_name\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, Union, Any\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from hporag.entity import BaseEntityExtractor\n",
    "class NuExtractor(BaseEntityExtractor):\n",
    "    \"\"\"Entity extraction using the NuExtract model with structured schema output.\n",
    "    \n",
    "    NuExtract extracts comprehensive phenotype-related information from clinical text,\n",
    "    aggregating findings by category (medical conditions, lab results, etc.).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_name: str = \"numind/NuExtract\", \n",
    "                 device: str = \"cuda:0\",\n",
    "                 max_length: int = 4000,\n",
    "                 schema: Optional[str] = None,\n",
    "                 examples: List[str] = None,\n",
    "                 cache_dir: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the NuExtract extractor.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name of the NuExtract model to use\n",
    "            device: Device to use for inference (e.g., \"cuda:0\", \"cpu\")\n",
    "            max_length: Maximum token length for input\n",
    "            schema: Custom schema for extraction (if None, uses default phenotype schema)\n",
    "            examples: List of example extractions in JSON string format\n",
    "            cache_dir: Directory to cache the model\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "        self.examples = examples or [\"\", \"\", \"\"]\n",
    "        self.cache_dir = cache_dir\n",
    "        \n",
    "        # Default schema for phenotype extraction\n",
    "        self.schema = schema or self._get_default_schema()\n",
    "        \n",
    "        # Initialize model\n",
    "        self._initialize_model()\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        \"\"\"Initialize the NuExtract model and tokenizer.\"\"\"\n",
    "        print(f\"Initializing NuExtract model from {self.model_name}...\")\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_name, \n",
    "                trust_remote_code=False,\n",
    "                cache_dir=self.cache_dir\n",
    "            )\n",
    "            \n",
    "            # Load model with appropriate precision\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_name, \n",
    "                torch_dtype=torch.bfloat16, \n",
    "                trust_remote_code=False,\n",
    "                cache_dir=self.cache_dir\n",
    "            )\n",
    "            \n",
    "            # Move model to specified device\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()  # Set to evaluation mode\n",
    "            print(f\"NuExtract model loaded successfully on {self.device}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing NuExtract model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _get_default_schema(self) -> str:\n",
    "        \"\"\"Get the default schema for comprehensive phenotype extraction.\"\"\"\n",
    "        schema = {\n",
    "            \"findings\": {\n",
    "                \"medical_conditions\": [],    # Medical diagnoses, diseases, disorders\n",
    "                \"syndromes\": [],             # Named syndromes and genetic disorders\n",
    "                \"lab_measurements\": [],      # Laboratory test results and abnormal values\n",
    "                \"symptoms\": [],              # Patient-reported symptoms\n",
    "                \"signs\": [],                 # Clinician-observed signs\n",
    "                \"anatomical_abnormalities\": [], # Structural or morphological abnormalities\n",
    "                \"developmental_features\": [], # Developmental delays, growth issues\n",
    "                \"neurological_features\": [], # Neurological findings and abnormalities\n",
    "                \"dysmorphic_features\": [],   # Distinctive physical features\n",
    "                \"congenital_anomalies\": [],  # Birth defects and anomalies\n",
    "                \"genetic_variants\": [],      # Genetic variants, mutations, chromosomal abnormalities\n",
    "                \"family_history\": [],        # Relevant family history findings\n",
    "                \"negated_findings\": [],      # Explicitly negated clinical findings\n",
    "                \"behavioral_features\": [],   # Behavioral and psychiatric features\n",
    "                \"metabolic_abnormalities\": [], # Metabolic disorders and findings\n",
    "                \"functional_limitations\": [], # Functional impairments and disabilities\n",
    "                \"diseases\" : []\n",
    "\n",
    "            }\n",
    "        }\n",
    "        return json.dumps(schema)\n",
    "\n",
    "    def extract_entities(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract entities from text using the NuExtract model.\n",
    "        \n",
    "        Args:\n",
    "            text: Clinical text to extract entities from\n",
    "            \n",
    "        Returns:\n",
    "            List of extracted entities as strings\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "            \n",
    "        # Get full structured extraction\n",
    "        extraction = self._extract_structured_data(text)\n",
    "        \n",
    "        # Aggregate all relevant findings into a single list for the pipeline\n",
    "        entities = []\n",
    "        print(extraction)\n",
    "        # Categories directly relevant to phenotypes\n",
    "        phenotype_relevant_categories = [\n",
    "            'medical_conditions', 'syndromes', 'lab_measurements', 'symptoms', 'signs',\n",
    "            'anatomical_abnormalities', 'developmental_features',\n",
    "            'neurological_features', 'dysmorphic_features',\n",
    "            'congenital_anomalies', 'genetic_variants',\n",
    "            'behavioral_features', 'metabolic_abnormalities',\n",
    "            'functional_limitations', 'diseases'\n",
    "        ]\n",
    "        \n",
    "        # Process findings if they exist\n",
    "        if 'findings' in extraction:\n",
    "            findings = extraction['findings']\n",
    "            \n",
    "            # Add entities from each relevant category\n",
    "            for category in phenotype_relevant_categories:\n",
    "                if category in findings and isinstance(findings[category], list):\n",
    "                    for item in findings[category]:\n",
    "                        if item and isinstance(item, str):\n",
    "                            entities.append(item)\n",
    "        \n",
    "        # Filter out duplicates while preserving order\n",
    "        unique_entities = []\n",
    "        seen = set()\n",
    "        for entity in entities:\n",
    "            entity_lower = entity.lower().strip()\n",
    "            if entity_lower and entity_lower not in seen:\n",
    "                seen.add(entity_lower)\n",
    "                unique_entities.append(entity)\n",
    "        \n",
    "        return unique_entities\n",
    "    \n",
    "    def _extract_structured_data(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform the actual extraction using NuExtract.\n",
    "        \n",
    "        Args:\n",
    "            text: Clinical text to extract from\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with structured extraction results\n",
    "        \"\"\"\n",
    "        # Prepare the input\n",
    "        schema_formatted = json.dumps(json.loads(self.schema), indent=4)\n",
    "        input_text = \"<|input|>\\n### Template:\\n\" + schema_formatted + \"\\n\"\n",
    "        \n",
    "        # Add examples if provided\n",
    "        for example in self.examples:\n",
    "            if example:\n",
    "                input_text += \"### Example:\\n\" + json.dumps(json.loads(example), indent=4) + \"\\n\"\n",
    "        \n",
    "        # Add the actual text to process\n",
    "        input_text += \"### Text:\\n\" + text + \"\\n<|output|>\\n\"\n",
    "        \n",
    "        # Tokenize and generate\n",
    "        try:\n",
    "            input_ids = self.tokenizer(\n",
    "                input_text, \n",
    "                return_tensors=\"pt\", \n",
    "                truncation=True, \n",
    "                max_length=self.max_length\n",
    "            ).to(self.device)\n",
    "            \n",
    "            # Generate output\n",
    "            with torch.no_grad():\n",
    "                output_ids = self.model.generate(\n",
    "                    **input_ids,\n",
    "                    max_new_tokens=1024,  # Ensure enough tokens for complex extractions\n",
    "                    temperature=0.1       # Lower temperature for more deterministic output\n",
    "                )\n",
    "                \n",
    "            # Decode output\n",
    "            output = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Extract the structured output\n",
    "            extraction_text = output.split(\"<|output|>\")[1].split(\"<|end-output|>\")[0].strip()\n",
    "            \n",
    "            # Parse the extraction as JSON\n",
    "            try:\n",
    "                extraction = json.loads(extraction_text)\n",
    "                return extraction\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing NuExtract output as JSON: {e}\")\n",
    "                print(f\"Raw output: {extraction_text}\")\n",
    "                return {}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during NuExtract inference: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def process_batch(self, texts: List[str]) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Process a batch of texts for entity extraction.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of clinical texts to process\n",
    "            \n",
    "        Returns:\n",
    "            List of lists containing extracted entities for each text\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            entities = self.extract_entities(text)\n",
    "            results.append(entities)\n",
    "        return results\n",
    "    \n",
    "    def extract_detailed_entities(self, text: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Extract entities and categorize them by type.\n",
    "        \n",
    "        Args:\n",
    "            text: Clinical text to extract entities from\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with categorized entities (medical_conditions, lab_measurements, etc.)\n",
    "        \"\"\"\n",
    "        extraction = self._extract_structured_data(text)\n",
    "        \n",
    "        result = {\n",
    "            'medical_conditions': [],\n",
    "            'lab_measurements': [],\n",
    "            'symptoms': [],\n",
    "            'anatomical_sites': [],\n",
    "            'genetic_variants': [],\n",
    "            'medications': [],\n",
    "            'diagnostic_procedures': [],\n",
    "            'diseases': []\n",
    "        }\n",
    "        \n",
    "        # Process findings if they exist\n",
    "        if 'findings' in extraction:\n",
    "            findings = extraction['findings']\n",
    "            \n",
    "            # Copy found categories to result\n",
    "            for category in result.keys():\n",
    "                if category in findings:\n",
    "                    result[category] = findings[category]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing NuExtract model from numind/NuExtract...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuExtract model loaded successfully on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnwu3/miniconda3/envs/hporag/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'findings': {'medical_conditions': ['myeloproliferative disorders', 'renal dysfunction'], 'syndromes': [], 'lab_measurements': ['urine microscopy', '24-hour urinary protein', 'serum creatinine', 'haemoglobin', 'white cell count', 'platelet count', 'serum lactate dehydrogenase (LDH)'], 'symptoms': ['frothy urine', 'leg oedema'], 'signs': ['bilateral pedal oedema', 'spleen palpable'], 'anatomical_abnormalities': ['mild renal parenchymal disease'], 'developmental_features': [], 'neurological_features': [], 'dysmorphic_features': [], 'congenital_anomalies': [], 'genetic_variants': [], 'family_history': ['no family member was suffering from similar illness'], 'negated_findings': ['viral markers (HbsAg, antihepatitis C virus, HIV) were negative', 'serum electrophoresis study and antinuclear antibodies were negative'], 'behavioral_features': [], 'metabolic_abnormalities': [], 'functional_limitations': [], 'diseases': ['myeloproliferative disorders', 'renal dysfunction']}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['myeloproliferative disorders',\n",
       " 'renal dysfunction',\n",
       " 'urine microscopy',\n",
       " '24-hour urinary protein',\n",
       " 'serum creatinine',\n",
       " 'haemoglobin',\n",
       " 'white cell count',\n",
       " 'platelet count',\n",
       " 'serum lactate dehydrogenase (LDH)',\n",
       " 'frothy urine',\n",
       " 'leg oedema',\n",
       " 'bilateral pedal oedema',\n",
       " 'spleen palpable',\n",
       " 'mild renal parenchymal disease']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = NuExtractor()\n",
    "extractor.extract_entities(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 56-year-old man presented to us with a history of frothy urine and leg oedema for the last 6 months. There was no history of fever, cough, shortness of breath and decrease urine output. There is no significant past medical history. No family member was suffering from similar illness. On examination, bilateral pedal oedema was present, the spleen was palpable 2 cm below left costal margin, rest examination was unremarkable. On further biochemical and haematological investigations, urine microscopy revealed significant proteinuria, a 24-hour urinary protein was 3.1 g and serum creatinine was 2.1 mg/dL. Complete blood count revealed haemoglobin (Hb)—13.0 g/dL, white cell count—28×109/L and platelet count of 842×109/L (table 1). The peripheral blood smear was suggestive of the leucoerythroblastic picture with few tear drop cells. Serum lactate dehydrogenase (LDH) was raised (1142 IU/L). To confirm the diagnosis of myeloproliferative disorders, bone marrow biopsy was done which was suggestive of PMF(figures 1 and 2). Our patient was classified in intermediate risk-1 according to Dynamic International Prognostic Scoring System. The patient was put on cytoreductive therapy with hydroxyurea (1000 mg/day). Subsequently, the patient was referred to nephrology department to determine the cause of progressive renal dysfunction. After 2 weeks, the patient presented in nephrology department with repeat urinalysis showing persistent nephrotic range proteinuria and serum creatinine of 2.3 mg/dL. Ultrasound abdomen was suggestive of the mild renal parenchymal disease. Viral markers (HbsAg, antihepatitis C virus, HIV) were negative. Serum electrophoresis study and antinuclear antibodies were negative (table 1). Renal biopsy was performed to know the underlying cause of rapidly declining renal dysfunction and proteinuria. Light microscopy section of kidney biopsy shows total 22 glomeruli out of which, 10 are globally sclerosed, 1 of the glomeruli shows ischaemic wrinkling and 2 of the glomeruli show segmental sclerosis (figure 3). All the medium-sized vessels and arterioles show medial thickening and luminal narrowing with hyaline arteriosclerosis (figure 4). \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hporag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
