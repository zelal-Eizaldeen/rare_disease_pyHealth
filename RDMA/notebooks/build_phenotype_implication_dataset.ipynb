{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "# Set the parent directory as the current directory\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded clinical data with 116 cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clinical notes: 100%|██████████| 116/116 [00:00<00:00, 20485.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2210 unique sentences from clinical texts\n",
      "Total sentences extracted: 2210\n",
      "\n",
      "Example sentences:\n",
      "1. A 44-year- old super-morbidly- obese man body mass index (BMI 63) underwent sleeve gastrectomy for weight loss and was found to have multiple adenomatous fundic gland polyps on final pathology.\n",
      "2. Subsequent workup included esophagogastroduodenoscopy which revealed innumerable polyps of the remaining gastric fundus and body consistent with fundic gland polyps, normal duodenum without polyps, and Barrett’s oesophagus.\n",
      "3. Colonoscopy was significant for innumerable polyps of varying sizes up to 1.\n",
      "4. 5 cm throughout the colon, with relative rectal sparing.\n",
      "5. Biopsies were consistent with tubular adenoma and hyperplastic polyps.\n",
      "\n",
      "Saved all sentences to clinical_sentences.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "\n",
    "def extract_clinical_sentences(input_file: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract sentences from clinical texts in a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to JSON file with clinical notes\n",
    "        \n",
    "    Returns:\n",
    "        List of sentences extracted from clinical texts\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "    \n",
    "    # Load JSON data\n",
    "    try:\n",
    "        with open(input_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Handle different possible input formats\n",
    "        if isinstance(data, dict):\n",
    "            # Format is {case_id: case_data}\n",
    "            # Convert string keys to integers if necessary\n",
    "            if all(isinstance(k, str) for k in data.keys()):\n",
    "                data = {int(k): v for k, v in data.items()}\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input format in {input_file}\")\n",
    "            \n",
    "        print(f\"Loaded clinical data with {len(data)} cases\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Invalid JSON format in file: {input_file}\")\n",
    "    \n",
    "    all_sentences = []\n",
    "    \n",
    "    # Process each clinical case\n",
    "    for case_id, case_data in tqdm(data.items(), desc=\"Processing clinical notes\"):\n",
    "        if not isinstance(case_data, dict):\n",
    "            print(f\"Warning: Case {case_id} data is not a dictionary. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Extract clinical text\n",
    "        clinical_text = case_data.get(\"clinical_text\", \"\")\n",
    "        if not clinical_text:\n",
    "            print(f\"Warning: Case {case_id} missing 'clinical_text' field. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Split into sentences\n",
    "        case_sentences = split_into_sentences(clinical_text)\n",
    "        \n",
    "        # Add to all sentences\n",
    "        all_sentences.extend(case_sentences)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_sentences = []\n",
    "    seen = set()\n",
    "    for sentence in all_sentences:\n",
    "        if sentence and sentence not in seen:\n",
    "            seen.add(sentence)\n",
    "            unique_sentences.append(sentence)\n",
    "    \n",
    "    print(f\"Extracted {len(unique_sentences)} unique sentences from clinical texts\")\n",
    "    return unique_sentences\n",
    "\n",
    "def split_into_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split clinical text into sentences using multiple delimiter rules.\n",
    "    \n",
    "    Args:\n",
    "        text: Clinical text to split into sentences\n",
    "        \n",
    "    Returns:\n",
    "        List of sentences\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # First split by common sentence terminators while preserving them\n",
    "    sentence_parts = []\n",
    "    for part in re.split(r'([.!?])', text):\n",
    "        if part.strip():\n",
    "            if part in '.!?':\n",
    "                if sentence_parts:\n",
    "                    sentence_parts[-1] += part\n",
    "            else:\n",
    "                sentence_parts.append(part.strip())\n",
    "    \n",
    "    # Then handle other clinical note delimiters like line breaks and semicolons\n",
    "    sentences = []\n",
    "    for part in sentence_parts:\n",
    "        # Split by semicolons and newlines\n",
    "        for subpart in re.split(r'[;\\n]', part):\n",
    "            if subpart.strip():\n",
    "                sentences.append(subpart.strip())\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your JSON file with clinical notes\n",
    "    input_file = \"data/dataset/mine_hpo.json\"\n",
    "    \n",
    "    try:\n",
    "        sentences = extract_clinical_sentences(input_file)\n",
    "        print(f\"Total sentences extracted: {len(sentences)}\")\n",
    "        \n",
    "        # Print a few examples\n",
    "        print(\"\\nExample sentences:\")\n",
    "        for i, sentence in enumerate(sentences[:5]):\n",
    "            print(f\"{i+1}. {sentence}\")\n",
    "            \n",
    "        # Optionally save to a text file\n",
    "        output_file = \"clinical_sentences.txt\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            for sentence in sentences:\n",
    "                f.write(f\"{sentence}\\n\")\n",
    "        print(f\"\\nSaved all sentences to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded clinical data with 116 cases\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eac734d67164dedb3d764a1312ad10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing clinical notes:   0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2210 unique sentences from clinical texts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c264f5dc76af4d6cbf5e48c3e5ff3327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h3>Sentence 1/2210:</h3><p style='background-color: #f0f0f0; padding: 10px;'>A 44-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def extract_clinical_sentences(input_file: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract sentences from clinical texts in a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to JSON file with clinical notes\n",
    "        \n",
    "    Returns:\n",
    "        List of sentences extracted from clinical texts\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "    \n",
    "    # Load JSON data\n",
    "    try:\n",
    "        with open(input_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Handle different possible input formats\n",
    "        if isinstance(data, dict):\n",
    "            # Format is {case_id: case_data}\n",
    "            # Convert string keys to integers if necessary\n",
    "            if all(isinstance(k, str) for k in data.keys()):\n",
    "                data = {int(k): v for k, v in data.items()}\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input format in {input_file}\")\n",
    "            \n",
    "        print(f\"Loaded clinical data with {len(data)} cases\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Invalid JSON format in file: {input_file}\")\n",
    "    \n",
    "    all_sentences = []\n",
    "    \n",
    "    # Process each clinical case\n",
    "    for case_id, case_data in tqdm(data.items(), desc=\"Processing clinical notes\"):\n",
    "        if not isinstance(case_data, dict):\n",
    "            print(f\"Warning: Case {case_id} data is not a dictionary. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Extract clinical text\n",
    "        clinical_text = case_data.get(\"clinical_text\", \"\")\n",
    "        if not clinical_text:\n",
    "            print(f\"Warning: Case {case_id} missing 'clinical_text' field. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Split into sentences\n",
    "        case_sentences = split_into_sentences(clinical_text)\n",
    "        \n",
    "        # Add to all sentences with case ID\n",
    "        for sentence in case_sentences:\n",
    "            all_sentences.append({\n",
    "                'case_id': str(case_id),\n",
    "                'sentence': sentence\n",
    "            })\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_sentences = []\n",
    "    seen = set()\n",
    "    for sentence_info in all_sentences:\n",
    "        sentence = sentence_info['sentence']\n",
    "        if sentence and sentence not in seen:\n",
    "            seen.add(sentence)\n",
    "            unique_sentences.append(sentence_info)\n",
    "    \n",
    "    print(f\"Extracted {len(unique_sentences)} unique sentences from clinical texts\")\n",
    "    return unique_sentences\n",
    "\n",
    "def split_into_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split clinical text into sentences using multiple delimiter rules.\n",
    "    \n",
    "    Args:\n",
    "        text: Clinical text to split into sentences\n",
    "        \n",
    "    Returns:\n",
    "        List of sentences\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # First split by common sentence terminators while preserving them\n",
    "    sentence_parts = []\n",
    "    for part in re.split(r'([.!?])', text):\n",
    "        if part.strip():\n",
    "            if part in '.!?':\n",
    "                if sentence_parts:\n",
    "                    sentence_parts[-1] += part\n",
    "            else:\n",
    "                sentence_parts.append(part.strip())\n",
    "    \n",
    "    # Then handle other clinical note delimiters like line breaks and semicolons\n",
    "    sentences = []\n",
    "    for part in sentence_parts:\n",
    "        # Split by semicolons and newlines\n",
    "        for subpart in re.split(r'[;\\n]', part):\n",
    "            if subpart.strip():\n",
    "                sentences.append(subpart.strip())\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "class PhenotypeAnnotator:\n",
    "    def __init__(self, sentences, output_file='phenotype_annotations.csv'):\n",
    "        \"\"\"\n",
    "        Initialize the phenotype annotator.\n",
    "        \n",
    "        Args:\n",
    "            sentences: List of sentence dictionaries with case_id and sentence\n",
    "            output_file: Path to output CSV file\n",
    "        \"\"\"\n",
    "        self.sentences = sentences\n",
    "        self.output_file = output_file\n",
    "        self.current_index = 0\n",
    "        self.annotations = []\n",
    "        \n",
    "        # Check if output file exists and load previous annotations\n",
    "        self.load_existing_annotations()\n",
    "        \n",
    "        # Create widgets\n",
    "        self.setup_widgets()\n",
    "        \n",
    "    def load_existing_annotations(self):\n",
    "        \"\"\"Load existing annotations if output file exists.\"\"\"\n",
    "        if os.path.exists(self.output_file):\n",
    "            try:\n",
    "                df = pd.read_csv(self.output_file)\n",
    "                self.annotations = df.to_dict('records')\n",
    "                \n",
    "                # Find the highest index that has been annotated\n",
    "                annotated_sentences = set(df['sentence'].tolist())\n",
    "                for i, sentence_info in enumerate(self.sentences):\n",
    "                    if sentence_info['sentence'] not in annotated_sentences:\n",
    "                        self.current_index = i\n",
    "                        break\n",
    "                else:\n",
    "                    # All sentences have been annotated\n",
    "                    self.current_index = len(self.sentences)\n",
    "                    \n",
    "                print(f\"Loaded {len(self.annotations)} previous annotations\")\n",
    "                print(f\"Continuing from index {self.current_index}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading previous annotations: {e}\")\n",
    "    \n",
    "    def setup_widgets(self):\n",
    "        \"\"\"Set up the Jupyter widgets for annotation.\"\"\"\n",
    "        # Sentence display\n",
    "        self.sentence_display = widgets.HTML(\n",
    "            value=\"<h3>Sentence:</h3><p style='background-color: #f0f0f0; padding: 10px;'></p>\"\n",
    "        )\n",
    "        \n",
    "        # Question 1: Does this sentence imply a phenotype?\n",
    "        self.implies_phenotype = widgets.RadioButtons(\n",
    "            options=[('Yes', True), ('No', False)],\n",
    "            description='Does this sentence imply a phenotype not already described explicitly in text?',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        # Question 2: What text implies a phenotype?\n",
    "        self.text_implies = widgets.Text(\n",
    "            description='Text that implies:',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Question 3: What phenotype?\n",
    "        self.phenotype = widgets.Text(\n",
    "            description='Phenotype:',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Navigation buttons\n",
    "        self.prev_button = widgets.Button(\n",
    "            description='Previous',\n",
    "            disabled=True,\n",
    "            button_style='info'\n",
    "        )\n",
    "        self.next_button = widgets.Button(\n",
    "            description='Save & Next',\n",
    "            button_style='success'\n",
    "        )\n",
    "        self.save_button = widgets.Button(\n",
    "            description='Save All',\n",
    "            button_style='danger'\n",
    "        )\n",
    "        \n",
    "        # Progress\n",
    "        self.progress = widgets.IntProgress(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=len(self.sentences),\n",
    "            description='Progress:',\n",
    "            style={'bar_color': '#0080ff'}\n",
    "        )\n",
    "        \n",
    "        # Set up callbacks\n",
    "        self.implies_phenotype.observe(self._on_implies_phenotype_change, names='value')\n",
    "        self.prev_button.on_click(self._on_prev_click)\n",
    "        self.next_button.on_click(self._on_next_click)\n",
    "        self.save_button.on_click(self._on_save_click)\n",
    "        \n",
    "        # Layout\n",
    "        self.main_box = widgets.VBox([\n",
    "            self.sentence_display,\n",
    "            self.implies_phenotype,\n",
    "            self.text_implies,\n",
    "            self.phenotype,\n",
    "            widgets.HBox([self.prev_button, self.next_button, self.save_button]),\n",
    "            self.progress\n",
    "        ])\n",
    "    \n",
    "    def _on_implies_phenotype_change(self, change):\n",
    "        \"\"\"Enable/disable text fields based on implies_phenotype selection.\"\"\"\n",
    "        if change['new']:  # If Yes\n",
    "            self.text_implies.disabled = False\n",
    "            self.phenotype.disabled = False\n",
    "        else:  # If No\n",
    "            self.text_implies.disabled = True\n",
    "            self.phenotype.disabled = True\n",
    "            # Clear the fields\n",
    "            self.text_implies.value = ''\n",
    "            self.phenotype.value = ''\n",
    "    \n",
    "    def _on_prev_click(self, b):\n",
    "        \"\"\"Handle previous button click.\"\"\"\n",
    "        if self.current_index > 0:\n",
    "            self.current_index -= 1\n",
    "            self._update_display()\n",
    "    \n",
    "    def _on_next_click(self, b):\n",
    "        \"\"\"Handle next button click.\"\"\"\n",
    "        self._save_current_annotation()\n",
    "        if self.current_index < len(self.sentences) - 1:\n",
    "            self.current_index += 1\n",
    "            self._update_display()\n",
    "        else:\n",
    "            # End of sentences\n",
    "            self._save_annotations()\n",
    "            self.sentence_display.value = \"<h3>Annotation Complete!</h3><p>All sentences have been annotated.</p>\"\n",
    "            self.implies_phenotype.disabled = True\n",
    "            self.text_implies.disabled = True\n",
    "            self.phenotype.disabled = True\n",
    "            self.next_button.disabled = True\n",
    "    \n",
    "    def _on_save_click(self, b):\n",
    "        \"\"\"Handle save button click.\"\"\"\n",
    "        self._save_current_annotation()\n",
    "        self._save_annotations()\n",
    "        print(f\"Annotations saved to {self.output_file}\")\n",
    "    \n",
    "    def _save_current_annotation(self):\n",
    "        \"\"\"Save the current annotation.\"\"\"\n",
    "        if self.current_index < len(self.sentences):\n",
    "            sentence_info = self.sentences[self.current_index]\n",
    "            \n",
    "            # Check if this sentence has already been annotated\n",
    "            for i, annotation in enumerate(self.annotations):\n",
    "                if annotation['sentence'] == sentence_info['sentence']:\n",
    "                    # Update existing annotation\n",
    "                    self.annotations[i] = {\n",
    "                        'case_id': sentence_info['case_id'],\n",
    "                        'sentence': sentence_info['sentence'],\n",
    "                        'implies_phenotype': self.implies_phenotype.value,\n",
    "                        'text_implies': self.text_implies.value if self.implies_phenotype.value else '',\n",
    "                        'phenotype': self.phenotype.value if self.implies_phenotype.value else ''\n",
    "                    }\n",
    "                    break\n",
    "            else:\n",
    "                # Add new annotation\n",
    "                self.annotations.append({\n",
    "                    'case_id': sentence_info['case_id'],\n",
    "                    'sentence': sentence_info['sentence'],\n",
    "                    'implies_phenotype': self.implies_phenotype.value,\n",
    "                    'text_implies': self.text_implies.value if self.implies_phenotype.value else '',\n",
    "                    'phenotype': self.phenotype.value if self.implies_phenotype.value else ''\n",
    "                })\n",
    "    \n",
    "    def _save_annotations(self):\n",
    "        \"\"\"Save all annotations to CSV file.\"\"\"\n",
    "        df = pd.DataFrame(self.annotations)\n",
    "        df.to_csv(self.output_file, index=False)\n",
    "    \n",
    "    def _update_display(self):\n",
    "        \"\"\"Update the display for the current sentence.\"\"\"\n",
    "        if self.current_index < len(self.sentences):\n",
    "            sentence_info = self.sentences[self.current_index]\n",
    "            self.sentence_display.value = f\"<h3>Sentence {self.current_index + 1}/{len(self.sentences)}:</h3>\" \\\n",
    "                                        f\"<p style='background-color: #f0f0f0; padding: 10px;'>{sentence_info['sentence']}</p>\" \\\n",
    "                                        f\"<p>Case ID: {sentence_info['case_id']}</p>\"\n",
    "            \n",
    "            # Check if this sentence has been annotated before\n",
    "            for annotation in self.annotations:\n",
    "                if annotation['sentence'] == sentence_info['sentence']:\n",
    "                    # Load existing annotation\n",
    "                    self.implies_phenotype.value = annotation['implies_phenotype']\n",
    "                    self.text_implies.value = annotation['text_implies']\n",
    "                    self.phenotype.value = annotation['phenotype']\n",
    "                    break\n",
    "            else:\n",
    "                # Reset fields\n",
    "                self.implies_phenotype.value = False\n",
    "                self.text_implies.value = ''\n",
    "                self.phenotype.value = ''\n",
    "            \n",
    "            # Update UI based on implies_phenotype value\n",
    "            self.text_implies.disabled = not self.implies_phenotype.value\n",
    "            self.phenotype.disabled = not self.implies_phenotype.value\n",
    "            \n",
    "            # Update progress\n",
    "            self.progress.value = self.current_index\n",
    "            \n",
    "            # Update button states\n",
    "            self.prev_button.disabled = (self.current_index == 0)\n",
    "            self.next_button.disabled = False\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the annotation process.\"\"\"\n",
    "        self._update_display()\n",
    "        display(self.main_box)\n",
    "\n",
    "# Example usage\n",
    "def start_annotation(input_file, output_file='phenotype_annotations.csv'):\n",
    "    \"\"\"Start the annotation process for a clinical text file.\"\"\"\n",
    "    sentences = extract_clinical_sentences(input_file)\n",
    "    annotator = PhenotypeAnnotator(sentences, output_file)\n",
    "    annotator.start()\n",
    "    return annotator\n",
    "\n",
    "# You would use this in your notebook with:\n",
    "annotator = start_annotation('data/dataset/mine_hpo.json', 'test_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded clinical data with 116 cases\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b2e93748b04793b8962a80b10ea98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing clinical notes:   0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2210 unique sentences from clinical texts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e5280e606f4c9181c17aa923a4a86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h3>Sentence 1/2210:</h3><p style='background-color: #f0f0f0; padding: 15px; max-wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def extract_clinical_sentences(input_file: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract sentences from clinical texts in a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to JSON file with clinical notes\n",
    "        \n",
    "    Returns:\n",
    "        List of sentences extracted from clinical texts\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n",
    "    \n",
    "    # Load JSON data\n",
    "    try:\n",
    "        with open(input_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Handle different possible input formats\n",
    "        if isinstance(data, dict):\n",
    "            # Format is {case_id: case_data}\n",
    "            # Convert string keys to integers if necessary\n",
    "            if all(isinstance(k, str) for k in data.keys()):\n",
    "                data = {int(k): v for k, v in data.items()}\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input format in {input_file}\")\n",
    "            \n",
    "        print(f\"Loaded clinical data with {len(data)} cases\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Invalid JSON format in file: {input_file}\")\n",
    "    \n",
    "    all_sentences = []\n",
    "    \n",
    "    # Process each clinical case\n",
    "    for case_id, case_data in tqdm(data.items(), desc=\"Processing clinical notes\"):\n",
    "        if not isinstance(case_data, dict):\n",
    "            print(f\"Warning: Case {case_id} data is not a dictionary. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Extract clinical text\n",
    "        clinical_text = case_data.get(\"clinical_text\", \"\")\n",
    "        if not clinical_text:\n",
    "            print(f\"Warning: Case {case_id} missing 'clinical_text' field. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Split into sentences\n",
    "        case_sentences = split_into_sentences(clinical_text)\n",
    "        \n",
    "        # Add to all sentences with case ID\n",
    "        for sentence in case_sentences:\n",
    "            all_sentences.append({\n",
    "                'case_id': str(case_id),\n",
    "                'sentence': sentence\n",
    "            })\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_sentences = []\n",
    "    seen = set()\n",
    "    for sentence_info in all_sentences:\n",
    "        sentence = sentence_info['sentence']\n",
    "        if sentence and sentence not in seen:\n",
    "            seen.add(sentence)\n",
    "            unique_sentences.append(sentence_info)\n",
    "    \n",
    "    print(f\"Extracted {len(unique_sentences)} unique sentences from clinical texts\")\n",
    "    return unique_sentences\n",
    "\n",
    "def split_into_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split clinical text into sentences using multiple delimiter rules.\n",
    "    \n",
    "    Args:\n",
    "        text: Clinical text to split into sentences\n",
    "        \n",
    "    Returns:\n",
    "        List of sentences\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # First split by common sentence terminators while preserving them\n",
    "    sentence_parts = []\n",
    "    for part in re.split(r'([.!?])', text):\n",
    "        if part.strip():\n",
    "            if part in '.!?':\n",
    "                if sentence_parts:\n",
    "                    sentence_parts[-1] += part\n",
    "            else:\n",
    "                sentence_parts.append(part.strip())\n",
    "    \n",
    "    # Then handle other clinical note delimiters like line breaks and semicolons\n",
    "    sentences = []\n",
    "    for part in sentence_parts:\n",
    "        # Split by semicolons and newlines\n",
    "        for subpart in re.split(r'[;\\n]', part):\n",
    "            if subpart.strip():\n",
    "                sentences.append(subpart.strip())\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "class PhenotypeAnnotator:\n",
    "    def __init__(self, sentences, output_file='phenotype_annotations.csv'):\n",
    "        \"\"\"\n",
    "        Initialize the phenotype annotator.\n",
    "        \n",
    "        Args:\n",
    "            sentences: List of sentence dictionaries with case_id and sentence\n",
    "            output_file: Path to output CSV file\n",
    "        \"\"\"\n",
    "        self.sentences = sentences\n",
    "        self.output_file = output_file\n",
    "        self.current_index = 0\n",
    "        self.annotations = []\n",
    "        \n",
    "        # Check if output file exists and load previous annotations\n",
    "        self.load_existing_annotations()\n",
    "        \n",
    "        # Create widgets\n",
    "        self.setup_widgets()\n",
    "        \n",
    "    def load_existing_annotations(self):\n",
    "        \"\"\"Load existing annotations if output file exists.\"\"\"\n",
    "        if os.path.exists(self.output_file):\n",
    "            try:\n",
    "                df = pd.read_csv(self.output_file)\n",
    "                self.annotations = df.to_dict('records')\n",
    "                \n",
    "                # Find the highest index that has been annotated\n",
    "                annotated_sentences = set(df['sentence'].tolist())\n",
    "                for i, sentence_info in enumerate(self.sentences):\n",
    "                    if sentence_info['sentence'] not in annotated_sentences:\n",
    "                        self.current_index = i\n",
    "                        break\n",
    "                else:\n",
    "                    # All sentences have been annotated\n",
    "                    self.current_index = len(self.sentences)\n",
    "                    \n",
    "                print(f\"Loaded {len(self.annotations)} previous annotations\")\n",
    "                print(f\"Continuing from index {self.current_index}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading previous annotations: {e}\")\n",
    "    \n",
    "    def setup_widgets(self):\n",
    "        \"\"\"Set up the Jupyter widgets for annotation.\"\"\"\n",
    "        # Sentence display with increased height for better visibility\n",
    "        self.sentence_display = widgets.HTML(\n",
    "            value=\"<h3>Sentence:</h3><p style='background-color: #f0f0f0; padding: 15px; max-width: 100%; word-wrap: break-word;'></p>\"\n",
    "        )\n",
    "        \n",
    "        # Question 1: Does this sentence imply a phenotype?\n",
    "        self.q1_label = widgets.HTML(\n",
    "            value=\"<p style='font-weight: bold; margin-bottom: 5px;'>Question 1: Does this sentence or context imply a phenotype that doesn't already explicitly exist in the text?</p>\"\n",
    "        )\n",
    "        self.implies_phenotype = widgets.RadioButtons(\n",
    "            options=[('Yes', True), ('No', False)],\n",
    "            description='Answer:',\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "        # Question 2: What text implies a phenotype?\n",
    "        self.q2_label = widgets.HTML(\n",
    "            value=\"<p style='font-weight: bold; margin-bottom: 5px; margin-top: 15px;'>Question 2: What specific piece of text implies a phenotype?</p>\"\n",
    "        )\n",
    "        self.text_implies = widgets.Text(\n",
    "            description='Answer:',\n",
    "            disabled=True,\n",
    "            layout=widgets.Layout(width='80%')\n",
    "        )\n",
    "        \n",
    "        # Question 3: What phenotype?\n",
    "        self.q3_label = widgets.HTML(\n",
    "            value=\"<p style='font-weight: bold; margin-bottom: 5px; margin-top: 15px;'>Question 3: What phenotype is implied?</p>\"\n",
    "        )\n",
    "        self.phenotype = widgets.Text(\n",
    "            description='Answer:',\n",
    "            disabled=True,\n",
    "            layout=widgets.Layout(width='80%')\n",
    "        )\n",
    "        \n",
    "        # Navigation buttons with increased width\n",
    "        button_layout = widgets.Layout(width='150px', height='40px')\n",
    "        self.prev_button = widgets.Button(\n",
    "            description='Previous',\n",
    "            disabled=True,\n",
    "            button_style='info',\n",
    "            layout=button_layout\n",
    "        )\n",
    "        self.next_button = widgets.Button(\n",
    "            description='Save & Next',\n",
    "            button_style='success',\n",
    "            layout=button_layout\n",
    "        )\n",
    "        self.save_button = widgets.Button(\n",
    "            description='Save All',\n",
    "            button_style='danger',\n",
    "            layout=button_layout\n",
    "        )\n",
    "        \n",
    "        # Progress bar with increased width\n",
    "        self.progress = widgets.IntProgress(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=len(self.sentences),\n",
    "            description='Progress:',\n",
    "            style={'bar_color': '#0080ff'},\n",
    "            layout=widgets.Layout(width='50%', height='30px')\n",
    "        )\n",
    "        \n",
    "        # Set up callbacks\n",
    "        self.implies_phenotype.observe(self._on_implies_phenotype_change, names='value')\n",
    "        self.prev_button.on_click(self._on_prev_click)\n",
    "        self.next_button.on_click(self._on_next_click)\n",
    "        self.save_button.on_click(self._on_save_click)\n",
    "        \n",
    "        # Layout with better spacing and grouping\n",
    "        self.main_box = widgets.VBox([\n",
    "            self.sentence_display,\n",
    "            widgets.HTML(value=\"<hr>\"),  # Add a separator\n",
    "            self.q1_label,\n",
    "            self.implies_phenotype,\n",
    "            self.q2_label,\n",
    "            self.text_implies,\n",
    "            self.q3_label,\n",
    "            self.phenotype,\n",
    "            widgets.HTML(value=\"<hr>\"),  # Add a separator\n",
    "            widgets.HBox([self.prev_button, self.next_button, self.save_button], \n",
    "                        layout=widgets.Layout(justify_content='space-around', margin='20px 0px')),\n",
    "            self.progress\n",
    "        ], layout=widgets.Layout(width='100%', padding='10px'))\n",
    "    \n",
    "    def _on_implies_phenotype_change(self, change):\n",
    "        \"\"\"Enable/disable text fields based on implies_phenotype selection.\"\"\"\n",
    "        if change['new']:  # If Yes\n",
    "            self.text_implies.disabled = False\n",
    "            self.phenotype.disabled = False\n",
    "        else:  # If No\n",
    "            self.text_implies.disabled = True\n",
    "            self.phenotype.disabled = True\n",
    "            # Clear the fields\n",
    "            self.text_implies.value = ''\n",
    "            self.phenotype.value = ''\n",
    "    \n",
    "    def _on_prev_click(self, b):\n",
    "        \"\"\"Handle previous button click.\"\"\"\n",
    "        if self.current_index > 0:\n",
    "            self.current_index -= 1\n",
    "            self._update_display()\n",
    "    \n",
    "    def _on_next_click(self, b):\n",
    "        \"\"\"Handle next button click.\"\"\"\n",
    "        self._save_current_annotation()\n",
    "        if self.current_index < len(self.sentences) - 1:\n",
    "            self.current_index += 1\n",
    "            self._update_display()\n",
    "        else:\n",
    "            # End of sentences\n",
    "            self._save_annotations()\n",
    "            self.sentence_display.value = \"<h3>Annotation Complete!</h3><p>All sentences have been annotated.</p>\"\n",
    "            self.implies_phenotype.disabled = True\n",
    "            self.text_implies.disabled = True\n",
    "            self.phenotype.disabled = True\n",
    "            self.next_button.disabled = True\n",
    "    \n",
    "    def _on_save_click(self, b):\n",
    "        \"\"\"Handle save button click.\"\"\"\n",
    "        self._save_current_annotation()\n",
    "        self._save_annotations()\n",
    "        print(f\"Annotations saved to {self.output_file}\")\n",
    "    \n",
    "    def _save_current_annotation(self):\n",
    "        \"\"\"Save the current annotation.\"\"\"\n",
    "        if self.current_index < len(self.sentences):\n",
    "            sentence_info = self.sentences[self.current_index]\n",
    "            \n",
    "            # Check if this sentence has already been annotated\n",
    "            for i, annotation in enumerate(self.annotations):\n",
    "                if annotation['sentence'] == sentence_info['sentence']:\n",
    "                    # Update existing annotation\n",
    "                    self.annotations[i] = {\n",
    "                        'case_id': sentence_info['case_id'],\n",
    "                        'sentence': sentence_info['sentence'],\n",
    "                        'implies_phenotype': self.implies_phenotype.value,\n",
    "                        'text_implies': self.text_implies.value if self.implies_phenotype.value else '',\n",
    "                        'phenotype': self.phenotype.value if self.implies_phenotype.value else ''\n",
    "                    }\n",
    "                    break\n",
    "            else:\n",
    "                # Add new annotation\n",
    "                self.annotations.append({\n",
    "                    'case_id': sentence_info['case_id'],\n",
    "                    'sentence': sentence_info['sentence'],\n",
    "                    'implies_phenotype': self.implies_phenotype.value,\n",
    "                    'text_implies': self.text_implies.value if self.implies_phenotype.value else '',\n",
    "                    'phenotype': self.phenotype.value if self.implies_phenotype.value else ''\n",
    "                })\n",
    "    \n",
    "    def _save_annotations(self):\n",
    "        \"\"\"Save all annotations to CSV file.\"\"\"\n",
    "        df = pd.DataFrame(self.annotations)\n",
    "        df.to_csv(self.output_file, index=False)\n",
    "    \n",
    "    def _update_display(self):\n",
    "        \"\"\"Update the display for the current sentence.\"\"\"\n",
    "        if self.current_index < len(self.sentences):\n",
    "            sentence_info = self.sentences[self.current_index]\n",
    "            self.sentence_display.value = f\"<h3>Sentence {self.current_index + 1}/{len(self.sentences)}:</h3>\" \\\n",
    "                                        f\"<p style='background-color: #f0f0f0; padding: 15px; max-width: 100%; word-wrap: break-word;'>{sentence_info['sentence']}</p>\" \\\n",
    "                                        f\"<p>Case ID: {sentence_info['case_id']}</p>\"\n",
    "            \n",
    "            # Check if this sentence has been annotated before\n",
    "            for annotation in self.annotations:\n",
    "                if annotation['sentence'] == sentence_info['sentence']:\n",
    "                    # Load existing annotation\n",
    "                    self.implies_phenotype.value = annotation['implies_phenotype']\n",
    "                    self.text_implies.value = annotation['text_implies']\n",
    "                    self.phenotype.value = annotation['phenotype']\n",
    "                    break\n",
    "            else:\n",
    "                # Reset fields\n",
    "                self.implies_phenotype.value = False\n",
    "                self.text_implies.value = ''\n",
    "                self.phenotype.value = ''\n",
    "            \n",
    "            # Update UI based on implies_phenotype value\n",
    "            self.text_implies.disabled = not self.implies_phenotype.value\n",
    "            self.phenotype.disabled = not self.implies_phenotype.value\n",
    "            \n",
    "            # Update progress\n",
    "            self.progress.value = self.current_index\n",
    "            \n",
    "            # Update button states\n",
    "            self.prev_button.disabled = (self.current_index == 0)\n",
    "            self.next_button.disabled = False\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the annotation process.\"\"\"\n",
    "        self._update_display()\n",
    "        display(self.main_box)\n",
    "\n",
    "# Example usage\n",
    "def start_annotation(input_file, output_file='phenotype_annotations.csv', limit=None):\n",
    "    \"\"\"\n",
    "    Start the annotation process for a clinical text file.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to JSON file with clinical notes\n",
    "        output_file: Path to output CSV file\n",
    "        limit: Optional limit on number of sentences to annotate (for testing)\n",
    "    \n",
    "    Returns:\n",
    "        PhenotypeAnnotator instance\n",
    "    \"\"\"\n",
    "    sentences = extract_clinical_sentences(input_file)\n",
    "    \n",
    "    # Optionally limit the number of sentences (for testing)\n",
    "    if limit and limit > 0 and limit < len(sentences):\n",
    "        print(f\"Limiting to first {limit} sentences (out of {len(sentences)} total)\")\n",
    "        sentences = sentences[:limit]\n",
    "        \n",
    "    annotator = PhenotypeAnnotator(sentences, output_file)\n",
    "    annotator.start()\n",
    "    return annotator\n",
    "\n",
    "# You would use this in your notebook with:\n",
    "annotator = start_annotation('data/dataset/mine_hpo.json', 'test_annotations.csv')\n",
    "# Or for testing with limited sentences:\n",
    "# annotator = start_annotation('path/to/your/mine_hpo.json', 'your_annotations.csv', limit=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hporag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
