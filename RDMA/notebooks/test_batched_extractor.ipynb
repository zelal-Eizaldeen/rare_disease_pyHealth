{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "# Set the parent directory as the current directory\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import read_json_file, print_json_structure\n",
    "hpo_data = read_json_file('data/dataset/mine_hpo.json')\n",
    "print(len(hpo_data))\n",
    "# print_json_structure(hpo_data)\n",
    "truth = hpo_data[\"53\"][\"phenotypes\"]\n",
    "# sample 5 texts and their ground truth phenotypes for testing.\n",
    "ids = [\"53\", \"54\", \"55\", \"56\", \"57\"] \n",
    "texts = []\n",
    "ground_truths = []\n",
    "for id in ids:\n",
    "    text = hpo_data[id][\"clinical_text\"]\n",
    "    texts.append(text)\n",
    "    truth = hpo_data[id][\"phenotypes\"]\n",
    "    ground_truth = []\n",
    "    for item in truth:\n",
    "        ground_truth.append(item[\"phenotype_name\"])\n",
    "    ground_truths.append(ground_truth)\n",
    "\n",
    "    sanity_check_list = []\n",
    "    for item in ground_truth:\n",
    "        # print(item)\n",
    "        if item in text:\n",
    "            sanity_check_list.append(item)\n",
    "    print(\"Pairwise checks:\")\n",
    "    print(len(sanity_check_list))\n",
    "    print(len(truth))\n",
    "# ground_truth = []\n",
    "# for item in truth:\n",
    "#     ground_truth.append(item[\"phenotype_name\"])\n",
    "# benchmark text runtime\n",
    "text = hpo_data[\"53\"][\"clinical_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mistral_llm_client():\n",
    "    \"\"\"\n",
    "    Load a Mistral 24B LLM client configured with default cache directories\n",
    "    and assigned to cuda:0 device.\n",
    "    \n",
    "    Returns:\n",
    "        LocalLLMClient: Initialized LLM client for Mistral 24B\n",
    "    \"\"\"\n",
    "    from utils.llm_client import LocalLLMClient\n",
    "    \n",
    "    # Default cache directory from mine_hpo.py\n",
    "    default_cache_dir = \"/u/zelalae2/scratch/rdma_cache\"\n",
    "    \n",
    "    # Initialize and return the client with specific configuration\n",
    "    llm_client = LocalLLMClient(\n",
    "        model_type=\"mistral_24b\",  # Explicitly request mistral_24b model\n",
    "        device=\"cuda:0\",           # Assign to first GPU (cuda:0)\n",
    "        cache_dir=default_cache_dir,\n",
    "        temperature=0.0001           # Default temperature from mine_hpo.py\n",
    "    )\n",
    "    \n",
    "    return llm_client\n",
    "\n",
    "llm_client = load_mistral_llm_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hporag.entity import RetrievalEnhancedEntityExtractor, RetrievalEnhancedEntityExtractorV2\n",
    "import json\n",
    "from hporag.entity import BaseEntityExtractor\n",
    "from utils.embedding import EmbeddingsManager\n",
    "import numpy as np\n",
    "# Load system prompts\n",
    "with open('data/prompts/system_prompts.json', 'r') as f:\n",
    "    prompts = json.load(f)\n",
    "    system_message_extraction = prompts.get(\"system_message_I\", \"\")\n",
    "    system_message_verification = prompts.get(\"system_message_II\", \"\")\n",
    "\n",
    "# Initialize embedding manager with MedEmbed using sentence transformers\n",
    "embedding_manager = EmbeddingsManager(\n",
    "    model_type=\"sentence_transformer\",\n",
    "    model_name=\"abhinand/MedEmbed-small-v0.1\",  # Medical-domain sentence transformer model\n",
    "    device=\"cuda:1\"\n",
    ")\n",
    "\n",
    "# Load embeddings\n",
    "embedded_documents = np.load('data/vector_stores/G2GHPO_metadata_medembed.npy', allow_pickle=True)\n",
    "llm_client.temperature = 0.001  # Lower temperature for more precise extraction\n",
    "# Initialize the retrieval-enhanced extractor\n",
    "retrieval_extractor = RetrievalEnhancedEntityExtractor(\n",
    "    llm_client=llm_client,\n",
    "    embedding_manager=embedding_manager,\n",
    "    embedded_documents=embedded_documents,\n",
    "    system_message=system_message_extraction,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "retrieval_extractor_v2 = RetrievalEnhancedEntityExtractorV2(\n",
    "    llm_client=llm_client,\n",
    "    embedding_manager=embedding_manager,\n",
    "    embedded_documents=embedded_documents,\n",
    "    system_message=system_message_extraction,\n",
    "    max_batch_size=32,\n",
    "    top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1m24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retr_v1 = retrieval_extractor.extract_entities(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_batch_size = 48, 1m 2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retr_v2 = retrieval_extractor_v2.extract_entities(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(retr_v1))\n",
    "print(len(retr_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_method1(list1, list2):\n",
    "    return list(set(list1) & set(list2))\n",
    "print(len(intersection_method1(retr_v1, retr_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disjoint_elements(list1, list2):\n",
    "    # Convert to sets for efficient operations\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    \n",
    "    # Symmetric difference finds elements in either set, but not in both\n",
    "    return list(set1 ^ set2)\n",
    "\n",
    "# Example usage\n",
    "a = [1, 2, 3, 4, 5]\n",
    "b = [4, 5, 6, 7, 8]\n",
    "\n",
    "print(disjoint_elements(retr_v1, retr_v2))  # [1, 2, 3, 6, 7, 8]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hporag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
