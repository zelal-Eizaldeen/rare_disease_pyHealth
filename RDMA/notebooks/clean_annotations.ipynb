{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0215f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "# Set the parent directory as the current directory\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd51697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/johnwu3/projects/rare_disease/workspace/repos/RareDiseaseMention/mimic_rare_disease_annotations.json...\n",
      "Dataset contains 312 documents\n",
      "Total annotations: 1073\n",
      "Processed dataset saved to public_data/rd_annos_public.json\n",
      "Processing data/dataset/filtered_rd_annos_updated_adam.json...\n",
      "Dataset contains 117 documents\n",
      "Total annotations: 333\n",
      "Processed dataset saved to public_data/filtered_rd_annos_public.json\n",
      "File not found: data/dataset/reannotated_rd_annos.json\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def process_dataset(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Process a dataset by removing the 'text' field from each document.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to the input JSON file\n",
    "        output_path: Path to save the processed JSON file\n",
    "    \"\"\"\n",
    "    print(f\"Processing {input_path}...\")\n",
    "    \n",
    "    try:\n",
    "        # Read the JSON file\n",
    "        with open(input_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"Dataset contains {len(data)} documents\")\n",
    "        \n",
    "        # Process each document to remove the text field\n",
    "        processed_data = {}\n",
    "        total_annotations = 0\n",
    "        \n",
    "        for doc_id, doc_data in data.items():\n",
    "            # Create a copy of the document data\n",
    "            processed_doc = dict(doc_data)\n",
    "            \n",
    "            # Remove the text field if it exists\n",
    "            if 'note_details' in processed_doc and 'text' in processed_doc['note_details']:\n",
    "                del processed_doc['note_details']['text']\n",
    "            \n",
    "            # Count annotations\n",
    "            if 'annotations' in processed_doc:\n",
    "                total_annotations += len(processed_doc['annotations'])\n",
    "            \n",
    "            # Store processed document\n",
    "            processed_data[doc_id] = processed_doc\n",
    "        \n",
    "        print(f\"Total annotations: {total_annotations}\")\n",
    "        \n",
    "        # Make sure the output directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # Save the processed data\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(processed_data, f, indent=2)\n",
    "        \n",
    "        print(f\"Processed dataset saved to {output_path}\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Create the output directory\n",
    "    os.makedirs(\"public_data\", exist_ok=True)\n",
    "    \n",
    "    # Define the files to process\n",
    "    files_to_process = [\n",
    "        (\"/home/johnwu3/projects/rare_disease/workspace/repos/RareDiseaseMention/mimic_rare_disease_annotations.json\", \"public_data/rd_annos_public.json\"),\n",
    "        (\"data/dataset/filtered_rd_annos_updated_adam.json\", \"public_data/filtered_rd_annos_public.json\"),\n",
    "        (\"data/dataset/reannotated_rd_annos.json\", \"public_data/reannotated_rd_annos_public.json\")\n",
    "    ]\n",
    "    \n",
    "    # Process each file\n",
    "    for input_path, output_path in files_to_process:\n",
    "        if os.path.exists(input_path):\n",
    "            process_dataset(input_path, output_path)\n",
    "        else:\n",
    "            print(f\"File not found: {input_path}\")\n",
    "    \n",
    "    print(\"Processing complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hporag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
